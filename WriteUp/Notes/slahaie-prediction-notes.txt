Notes on "Prediction Markets and Exponential Families"

The write-up assumes throughout that the underlying distribution is drawn from an exponential family. Note that according to my write-up, that assumption isn't necessary if we want to elicit or run a market for for the distribution's sufficient statistics. I have not checked whether the assumption can be done away with also for the results related to budgets.

The results related to budgets (Section 5) are really nice, but the assumption on the specific form of update (bottom of page 8) would be an easy target for difficult reviewers. The problem is that for some utility functions, it might not even be optimal for the agent to move the shares exactly in the direction of its beliefs. Miro Dudik has looked at this problem in detail but his results are too preliminary to share.

In several places in your write-up you talk about agents drawing samples to form an empirical estimate. Perhaps more could be done with this model of agent. The agents who have drawn more samples would have estimates with lower standard error. I wonder whether it could be interesting to model the agents with mean-variance utilities in this context, and understand how not just the agents' means but also the variance of their estimates are aggregated by the market. There could even be a cost associated with taking a sample. Related to this, perhaps the agents could have priors on the parameters; the natural choice would be the conjugate prior for the exponential family at hand. Let me stress that these are just hunches and the details might not work out.

There is an alternate proof of the arbitrage-free property that might be more informative. Define a "sure bet" to be a linear combination (i.e., portfolio) of securities that has constant payoff over outcomes. Then for any cost function market maker derived using convex duality as in Abernethy-Chen-Wortman, we have C(p+q) = C(p) + cons, where cons is the constant payoff from sure bet q.

One thing to be careful about is the domain of definition of the natural parameters, which could seem odd in the prediction market setting. For example, in a market for the first and second uncentered moments (i.e., E[x] and E[x^2]) the outstanding shares for the second moment must be non-negative, or else the share vector isn't a valid natural parameter for any distribution.

Exponential families have close connections with graphical models. I've been wondering whether that connection, based on sufficiency properties (as in the Pitman-Koopman-Darmois theorem) could be used to re-derive, hopefully more easily, the results in Hanson's "Logarithmic Market Scoring Rules for
Modular Combinatorial Information Aggregation".

Specific comments:
- I'm not crazy about the assumption of lower bounded security payoffs, since it eliminates nice distributions like the Gaussian. I understand the point though.
- I'm surprised "maximum entropy" never comes up in your write-up!
- Theorem 3 should make clear that it's referring to log loss.
- Equality (2) holds for any cost function market maker, not just LMSR. Then K becomes the Bregman divergence associated with the (convex) cost function. So the insights on trader impact can be generalized to reductions in Bregman divergence to true distribution.
- I don't quite understand the cloning attack described in the conclusion, specifically how an agent can "downweigh" future agent's bets. This sounds like Bayesian updating but that's not how the cost-function prediction market works. Perhaps it's related to the fact that the market is run over rounds with outcomes being drawn at each round, which is somewhat novel to your write-up (but very interesting).












 












